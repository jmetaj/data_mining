{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation and Model Training\n",
    "In this notebook, we will load the data, preprocess it, and train three classifiers: a Neural Network, a Random Forest, and a Bayesian Network. We will evaluate and compare their performances.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_processing import clean_combined_data  \n",
    "\n",
    "# Load and clean data\n",
    "combined_data = clean_combined_data()\n",
    "\n",
    "\n",
    "X = combined_data.drop(columns=['label', 'timestamp'])\n",
    "y = combined_data['label']\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Unique labels in y_test: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Number of unique classes: 12\n",
      "Epoch 1/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 3ms/step - accuracy: 0.8367 - loss: 0.5223 - val_accuracy: 0.8691 - val_loss: 0.4095\n",
      "Epoch 2/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m369s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.4398 - val_accuracy: 0.8695 - val_loss: 0.4043\n",
      "Epoch 3/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.4344 - val_accuracy: 0.8726 - val_loss: 0.3979\n",
      "Epoch 4/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 3ms/step - accuracy: 0.8617 - loss: 0.4318 - val_accuracy: 0.8729 - val_loss: 0.3965\n",
      "Epoch 5/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m364s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.4291 - val_accuracy: 0.8717 - val_loss: 0.3976\n",
      "Epoch 6/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.4281 - val_accuracy: 0.8728 - val_loss: 0.3958\n",
      "Epoch 7/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.4273 - val_accuracy: 0.8727 - val_loss: 0.3933\n",
      "Epoch 8/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m360s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.4260 - val_accuracy: 0.8733 - val_loss: 0.3948\n",
      "Epoch 9/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m357s\u001b[0m 3ms/step - accuracy: 0.8628 - loss: 0.4258 - val_accuracy: 0.8729 - val_loss: 0.3930\n",
      "Epoch 10/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m361s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.4254 - val_accuracy: 0.8726 - val_loss: 0.3937\n",
      "\u001b[1m60575/60575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m128s\u001b[0m 2ms/step - accuracy: 0.8736 - loss: 0.3896\n",
      "\u001b[1m60575/60575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 2ms/step\n",
      "Neural Network Accuracy: 0.8728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.86      0.80    359238\n",
      "           1       0.91      0.77      0.83     87592\n",
      "           2       0.41      0.13      0.20     76676\n",
      "           3       0.14      0.00      0.00     22897\n",
      "           4       0.00      0.00      0.00     20140\n",
      "           5       0.75      0.89      0.81    222327\n",
      "           6       0.99      1.00      0.99    870840\n",
      "           7       1.00      1.00      1.00    128693\n",
      "           8       0.75      0.86      0.80    118360\n",
      "           9       0.58      0.47      0.52     16772\n",
      "          10       0.39      0.24      0.29     12493\n",
      "          11       0.51      0.23      0.32      2371\n",
      "\n",
      "    accuracy                           0.87   1938399\n",
      "   macro avg       0.60      0.54      0.55   1938399\n",
      "weighted avg       0.85      0.87      0.85   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard # type: ignore\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure data is a numpy array and in float32 format for efficiency\n",
    "X_train_scaled = np.array(X_train_scaled, dtype='float32')\n",
    "y_train = np.array(y_train)\n",
    "X_test_scaled = np.array(X_test_scaled, dtype='float32')\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# Map labels to a continuous range starting from 0\n",
    "unique_labels = np.unique(y_train)\n",
    "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
    "\n",
    "\n",
    "y_train = np.array([label_mapping[label] for label in y_train])\n",
    "y_test = np.array([label_mapping[label] for label in y_test])\n",
    "\n",
    "\n",
    "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "print(\"Unique labels in y_test:\", np.unique(y_test))\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Number of unique classes:\", num_classes)\n",
    "\n",
    "# Build and train the neural network with the correct number of output units\n",
    "model = Sequential([\n",
    "    Dense(64, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Add early stopping to prevent overfitting and save time\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "# Add TensorBoard for monitoring\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "          callbacks=[early_stopping, tensorboard])\n",
    "\n",
    "\n",
    "nn_results = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred_nn = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "print(f'Neural Network Accuracy: {nn_results[1]:.4f}')\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81    359238\n",
      "           1       0.93      0.83      0.88     87592\n",
      "           2       0.57      0.07      0.13     76676\n",
      "           3       0.71      0.00      0.01     22897\n",
      "           4       0.62      0.01      0.02     20140\n",
      "           5       0.74      0.91      0.82    222327\n",
      "           6       0.99      1.00      0.99    870840\n",
      "           7       1.00      1.00      1.00    128693\n",
      "           8       0.78      0.87      0.82    118360\n",
      "           9       0.76      0.41      0.54     16772\n",
      "          10       0.75      0.19      0.31     12493\n",
      "          11       0.67      0.16      0.25      2371\n",
      "\n",
      "    accuracy                           0.88   1938399\n",
      "   macro avg       0.77      0.53      0.55   1938399\n",
      "weighted avg       0.87      0.88      0.86   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train the Random Forest \n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=50,  \n",
    "    max_depth=15,     \n",
    "    n_jobs=-1,        \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}')\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Network Accuracy: 0.7750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59    359238\n",
      "           1       0.62      0.61      0.62     87592\n",
      "           2       0.15      0.10      0.12     76676\n",
      "           3       0.00      0.00      0.00     22897\n",
      "           4       0.00      0.00      0.00     20140\n",
      "           5       0.55      0.93      0.69    222327\n",
      "           6       0.97      0.98      0.97    870840\n",
      "           7       0.92      0.98      0.95    128693\n",
      "           8       0.57      0.54      0.56    118360\n",
      "           9       0.35      0.11      0.17     16772\n",
      "          10       0.00      0.00      0.00     12493\n",
      "          11       0.13      0.01      0.01      2371\n",
      "\n",
      "    accuracy                           0.77   1938399\n",
      "   macro avg       0.41      0.40      0.39   1938399\n",
      "weighted avg       0.75      0.77      0.76   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Train the Gaussian Naive Bayes model\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(f'Bayesian Network Accuracy: {accuracy_score(y_test, y_pred_gnb):.4f}')\n",
    "print(classification_report(y_test, y_pred_gnb, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  Accuracy\n",
      "0    Neural Network  0.872773\n",
      "1     Random Forest  0.880909\n",
      "2  Bayesian Network  0.774960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'Model': ['Neural Network', 'Random Forest', 'Bayesian Network'],\n",
    "    'Accuracy': [nn_results[1], accuracy_score(y_test, y_pred_rf), accuracy_score(y_test, y_pred_gnb)],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
