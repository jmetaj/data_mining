{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_processing import clean_combined_data  \n",
    "\n",
    "# Load and clean data\n",
    "combined_data = clean_combined_data()\n",
    "\n",
    "\n",
    "X = combined_data.drop(columns=['label', 'timestamp'])\n",
    "y = combined_data['label']\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in y_train: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Unique labels in y_test: [ 0  1  2  3  4  5  6  7  8  9 10 11]\n",
      "Number of unique classes: 12\n",
      "Epoch 1/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 4ms/step - accuracy: 0.8494 - loss: 0.4735 - val_accuracy: 0.8777 - val_loss: 0.3750\n",
      "Epoch 2/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 3ms/step - accuracy: 0.8691 - loss: 0.4014 - val_accuracy: 0.8788 - val_loss: 0.3684\n",
      "Epoch 3/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3949 - val_accuracy: 0.8793 - val_loss: 0.3665\n",
      "Epoch 4/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m400s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.3929 - val_accuracy: 0.8798 - val_loss: 0.3646\n",
      "Epoch 5/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m390s\u001b[0m 3ms/step - accuracy: 0.8723 - loss: 0.3899 - val_accuracy: 0.8805 - val_loss: 0.3626\n",
      "Epoch 6/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3897 - val_accuracy: 0.8807 - val_loss: 0.3622\n",
      "Epoch 7/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 3ms/step - accuracy: 0.8731 - loss: 0.3871 - val_accuracy: 0.8799 - val_loss: 0.3637\n",
      "Epoch 8/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m389s\u001b[0m 3ms/step - accuracy: 0.8727 - loss: 0.3878 - val_accuracy: 0.8805 - val_loss: 0.3607\n",
      "Epoch 9/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m382s\u001b[0m 3ms/step - accuracy: 0.8732 - loss: 0.3867 - val_accuracy: 0.8808 - val_loss: 0.3621\n",
      "Epoch 10/10\n",
      "\u001b[1m113074/113074\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m379s\u001b[0m 3ms/step - accuracy: 0.8734 - loss: 0.3863 - val_accuracy: 0.8810 - val_loss: 0.3608\n",
      "\u001b[1m60575/60575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 2ms/step - accuracy: 0.8808 - loss: 0.3582\n",
      "\u001b[1m60575/60575\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 2ms/step\n",
      "Neural Network Accuracy: 0.8802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.86      0.81    359238\n",
      "           1       0.89      0.83      0.86     87592\n",
      "           2       0.46      0.14      0.21     76676\n",
      "           3       0.51      0.06      0.11     22897\n",
      "           4       0.44      0.02      0.04     20140\n",
      "           5       0.75      0.91      0.82    222327\n",
      "           6       0.99      1.00      0.99    870840\n",
      "           7       1.00      1.00      1.00    128693\n",
      "           8       0.77      0.87      0.82    118360\n",
      "           9       0.60      0.51      0.55     16772\n",
      "          10       0.49      0.31      0.38     12493\n",
      "          11       0.53      0.35      0.42      2371\n",
      "\n",
      "    accuracy                           0.88   1938399\n",
      "   macro avg       0.68      0.57      0.58   1938399\n",
      "weighted avg       0.87      0.88      0.86   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential # type: ignore\n",
    "from tensorflow.keras.layers import Dense, Dropout # type: ignore\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard # type: ignore\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Ensure that data is a numpy array \n",
    "X_train_scaled = np.array(X_train_scaled, dtype='float32')\n",
    "y_train = np.array(y_train)\n",
    "X_test_scaled = np.array(X_test_scaled, dtype='float32')\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "unique_labels = np.unique(y_train)\n",
    "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
    "\n",
    "\n",
    "y_train = np.array([label_mapping[label] for label in y_train])\n",
    "y_test = np.array([label_mapping[label] for label in y_test])\n",
    "\n",
    "\n",
    "print(\"Unique labels in y_train:\", np.unique(y_train))\n",
    "print(\"Unique labels in y_test:\", np.unique(y_test))\n",
    "\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(\"Number of unique classes:\", num_classes)\n",
    "\n",
    "# Build neural network \n",
    "model = Sequential([\n",
    "    Dense(128, input_shape=(X_train_scaled.shape[1],), activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')  \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs', histogram_freq=1)\n",
    "\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2,\n",
    "          callbacks=[early_stopping, tensorboard])\n",
    "\n",
    "\n",
    "nn_results = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred_nn = model.predict(X_test_scaled).argmax(axis=1)\n",
    "\n",
    "print(f'Neural Network Accuracy: {nn_results[1]:.4f}')\n",
    "print(classification_report(y_test, y_pred_nn))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.8809\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.81    359238\n",
      "           1       0.93      0.83      0.88     87592\n",
      "           2       0.57      0.07      0.13     76676\n",
      "           3       0.71      0.00      0.01     22897\n",
      "           4       0.62      0.01      0.01     20140\n",
      "           5       0.74      0.91      0.82    222327\n",
      "           6       0.99      1.00      0.99    870840\n",
      "           7       1.00      1.00      1.00    128693\n",
      "           8       0.78      0.87      0.82    118360\n",
      "           9       0.76      0.41      0.54     16772\n",
      "          10       0.75      0.19      0.31     12493\n",
      "          11       0.67      0.16      0.25      2371\n",
      "\n",
      "    accuracy                           0.88   1938399\n",
      "   macro avg       0.77      0.53      0.55   1938399\n",
      "weighted avg       0.87      0.88      0.86   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Random Forest \n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=50,  \n",
    "    max_depth=15,     \n",
    "    n_jobs=-1,        \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_rf = rf_clf.predict(X_test)\n",
    "print(f'Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}')\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bayesian Network Accuracy: 0.7750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.53      0.59    359238\n",
      "           1       0.62      0.61      0.62     87592\n",
      "           2       0.15      0.10      0.12     76676\n",
      "           3       0.00      0.00      0.00     22897\n",
      "           4       0.00      0.00      0.00     20140\n",
      "           5       0.55      0.93      0.69    222327\n",
      "           6       0.97      0.98      0.97    870840\n",
      "           7       0.92      0.98      0.95    128693\n",
      "           8       0.57      0.54      0.56    118360\n",
      "           9       0.35      0.11      0.17     16772\n",
      "          10       0.00      0.00      0.00     12493\n",
      "          11       0.13      0.01      0.01      2371\n",
      "\n",
      "    accuracy                           0.77   1938399\n",
      "   macro avg       0.41      0.40      0.39   1938399\n",
      "weighted avg       0.75      0.77      0.76   1938399\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Gaussian Naive Bayes model\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_gnb = gnb_clf.predict(X_test)\n",
    "print(f'Bayesian Network Accuracy: {accuracy_score(y_test, y_pred_gnb):.4f}')\n",
    "print(classification_report(y_test, y_pred_gnb, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Model  Accuracy\n",
      "0    Neural Network  0.880196\n",
      "1     Random Forest  0.880920\n",
      "2  Bayesian Network  0.774960\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "results = {\n",
    "    'Model': ['Neural Network', 'Random Forest', 'Bayesian Network'],\n",
    "    'Accuracy': [nn_results[1], accuracy_score(y_test, y_pred_rf), accuracy_score(y_test, y_pred_gnb)],\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
